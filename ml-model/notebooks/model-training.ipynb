{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Model Training & Evaluation (Baseline + Trees + XGB)\n",
    "Handles imbalance, runs CV, tunes threshold, exports ONNX, measures inference speed."
   ],
   "id": "a8cd0ca2bdf48390"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:04:06.883005Z",
     "start_time": "2025-11-23T14:04:06.877709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def resolve_project_relative(p: str | Path) -> Path:\n",
    "    p = Path(p)\n",
    "    if p.is_absolute():\n",
    "        return p\n",
    "\n",
    "    here = Path.cwd().resolve()\n",
    "    last_with_ml = None\n",
    "    root = here\n",
    "    while True:\n",
    "        if (root / 'ml-model').is_dir():\n",
    "            last_with_ml = root\n",
    "        if root == root.parent:\n",
    "            break\n",
    "        root = root.parent\n",
    "\n",
    "    if last_with_ml is not None:\n",
    "        return (last_with_ml / p).resolve()\n",
    "\n",
    "    # Fallback: just resolve from CWD\n",
    "    return (here / p).resolve()"
   ],
   "id": "b61c5aa560b2f125",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:04:08.551981Z",
     "start_time": "2025-11-23T14:04:06.946793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings, time, json\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, confusion_matrix, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib, yaml\n",
    "\n",
    "# strict deps – fail fast if anything is missing\n",
    "import xgboost as xgb\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import onnxruntime as ort\n",
    "from onnxmltools.convert import convert_xgboost\n",
    "from onnxconverter_common.data_types import FloatTensorType as FloatTensorType2  # for onnxmltools\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# --- CONFIG ---\n",
    "CFG_PATH = resolve_project_relative(Path('ml-model/config/training_config.yaml'))\n",
    "cfg = yaml.safe_load(CFG_PATH.read_text())\n",
    "\n",
    "np.random.seed(cfg['seed'])\n",
    "print('Config:', json.dumps(cfg, indent=2))"
   ],
   "id": "93a50b35d859842f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {\n",
      "  \"seed\": 42,\n",
      "  \"input_csv\": \"ml-model/data/creditcard.csv\",\n",
      "  \"use_time_feature\": false,\n",
      "  \"use_smote\": false,\n",
      "  \"test_size\": 0.2,\n",
      "  \"cv_splits\": 5,\n",
      "  \"scaler_amount_path\": \"ml-model/artifacts/amount_scaler.pkl\",\n",
      "  \"export_onnx\": true,\n",
      "  \"onnx_opset\": 15,\n",
      "  \"timing_samples\": 10000,\n",
      "  \"threshold\": null,\n",
      "  \"use_processed\": true,\n",
      "  \"processed_dir\": \"ml-model/processed\",\n",
      "  \"artifacts_dir\": \"ml-model/artifacts\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:04:08.696065Z",
     "start_time": "2025-11-23T14:04:08.660579Z"
    }
   },
   "source": [
    "P = resolve_project_relative(Path(cfg[\"processed_dir\"]))\n",
    "A = resolve_project_relative(Path(cfg[\"artifacts_dir\"]))\n",
    "\n",
    "Xtr_np = np.load(P / \"X_train_time80.npy\").astype(np.float32)\n",
    "y_train = np.load(P / \"y_train_time80.npy\").astype(np.int64)\n",
    "Xte_np = np.load(P / \"X_test_time20.npy\").astype(np.float32)\n",
    "y_test = np.load(P / \"y_test_time20.npy\").astype(np.int64)\n",
    "\n",
    "params = json.loads((A / \"feature_params.json\").read_text())\n",
    "feature_names = params[\"order\"]\n",
    "assert Xtr_np.shape[1] == len(feature_names) == Xte_np.shape[1], \"Feature dim/order mismatch.\"\n",
    "\n",
    "Xtr = pd.DataFrame(Xtr_np, columns=feature_names)\n",
    "Xte = pd.DataFrame(Xte_np, columns=feature_names)\n",
    "\n",
    "print({\n",
    "    \"Xtr\": Xtr.shape, \"Xte\": Xte.shape,\n",
    "    \"fraud_train\": int(y_train.sum()), \"fraud_test\": int(y_test.sum()),\n",
    "    \"features\": feature_names[-5:]  # tail preview\n",
    "})"
   ],
   "id": "a8e4a4f4f87c042d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Xtr': (227845, 31), 'Xte': (56962, 31), 'fraud_train': 417, 'fraud_test': 75, 'features': ['V27', 'V28', 'Amount_z', 'tod_sin', 'tod_cos']}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:04:08.839977Z",
     "start_time": "2025-11-23T14:04:08.825490Z"
    }
   },
   "source": [
    "y_train = np.asarray(y_train, dtype=np.int64).ravel()\n",
    "\n",
    "cnt = np.bincount(y_train, minlength=2)\n",
    "neg, pos = int(cnt[0]), int(cnt[1]) if cnt.size > 1 else 0\n",
    "ratio = neg / max(pos, 1)\n",
    "\n",
    "MODELS = {\n",
    "    \"lr\": LogisticRegression(\n",
    "        class_weight=\"balanced\", solver=\"liblinear\", max_iter=1000, random_state=cfg[\"seed\"]\n",
    "    ),\n",
    "    \"rf\": RandomForestClassifier(\n",
    "        n_estimators=500, class_weight=\"balanced\", n_jobs=-1, random_state=cfg[\"seed\"]\n",
    "    ),\n",
    "    \"xgb\": xgb.XGBClassifier(\n",
    "        n_estimators=700, max_depth=5, learning_rate=0.05,\n",
    "        subsample=0.9, colsample_bytree=0.9,\n",
    "        scale_pos_weight=ratio, tree_method=\"hist\", n_jobs=-1, random_state=cfg[\"seed\"]\n",
    "    ),\n",
    "}\n",
    "if cfg.get(\"use_smote\", False):\n",
    "    MODELS[\"lr_smote\"] = ImbPipeline(steps=[\n",
    "        (\"smote\", SMOTE(random_state=cfg[\"seed\"], k_neighbors=5)),\n",
    "        (\"clf\", LogisticRegression(solver=\"liblinear\", max_iter=1000, random_state=cfg[\"seed\"]))\n",
    "    ])\n"
   ],
   "id": "3f6d1ec8f9cbcb4d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:10:01.064755Z",
     "start_time": "2025-11-23T14:04:08.889886Z"
    }
   },
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def as_pipeline(est):\n",
    "    return est if isinstance(est, (Pipeline, ImbPipeline)) else Pipeline([(\"clf\", est)])\n",
    "\n",
    "def walk_forward_splits(n, k):\n",
    "    # split train window into k+1 contiguous blocks; k folds = (train->next block as val)\n",
    "    block = max(n // (k + 1), 1)\n",
    "    for i in range(k):\n",
    "        tr_end = block * (i + 1)\n",
    "        val_start = tr_end\n",
    "        val_end = block * (i + 2) if i < k - 1 else n\n",
    "        if val_start >= val_end:\n",
    "            break\n",
    "        yield np.arange(0, tr_end), np.arange(val_start, val_end)\n",
    "\n",
    "n = len(Xtr)\n",
    "wf = list(walk_forward_splits(n, cfg['cv_splits']))\n",
    "\n",
    "cv_results = {}\n",
    "for name, est in MODELS.items():\n",
    "    recs, f1s, aucs = [], [], []\n",
    "    for tr_idx, val_idx in wf:\n",
    "        X_tr = Xtr.iloc[tr_idx]\n",
    "        y_tr = y_train[tr_idx]  # numpy indexing\n",
    "\n",
    "        X_va = Xtr.iloc[val_idx]\n",
    "        y_va = y_train[val_idx] # numpy indexing\n",
    "\n",
    "\n",
    "# skip folds with no positives in validation\n",
    "        if (int(y_va.sum()) == 0):\n",
    "            continue\n",
    "\n",
    "        mdl = clone(as_pipeline(est)).fit(X_tr, y_tr)\n",
    "        yhat = mdl.predict(X_va)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(y_va, yhat, average=\"binary\", zero_division=0)\n",
    "        auc = roc_auc_score(y_va, mdl.predict_proba(X_va)[:, 1]) if hasattr(mdl, \"predict_proba\") else float(\"nan\")\n",
    "        recs.append(rec); f1s.append(f1); aucs.append(auc)\n",
    "\n",
    "    cv_results[name] = {\n",
    "        \"recall\": float(np.mean(recs)) if recs else 0.0,\n",
    "        \"f1\":     float(np.mean(f1s))   if f1s else 0.0,\n",
    "        \"roc_auc\": float(np.nanmean(aucs)) if aucs else float(\"nan\"),\n",
    "        \"folds_used\": len(recs)\n",
    "    }\n",
    "cv_results"
   ],
   "id": "ca47588ffd9db39a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': {'recall': 0.8761937601898712,\n",
       "  'f1': 0.12807214041303389,\n",
       "  'roc_auc': 0.9597639842630755,\n",
       "  'folds_used': 5},\n",
       " 'rf': {'recall': 0.643426510271133,\n",
       "  'f1': 0.7575686810471371,\n",
       "  'roc_auc': 0.9536663240101635,\n",
       "  'folds_used': 5},\n",
       " 'xgb': {'recall': 0.7906153034463668,\n",
       "  'f1': 0.8145975240100854,\n",
       "  'roc_auc': 0.9702198655298941,\n",
       "  'folds_used': 5}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:12:18.319666Z",
     "start_time": "2025-11-23T14:10:01.206487Z"
    }
   },
   "source": [
    "# --- TRAIN ALL ---\n",
    "trained = {name: Pipeline([(\"clf\", mdl)]) for name, mdl in MODELS.items()}\n",
    "trained = {n: m.fit(Xtr, y_train) for n, m in trained.items()}"
   ],
   "id": "41420c55734fde7c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:12:18.444338Z",
     "start_time": "2025-11-23T14:12:18.439043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#p\n",
    "from sklearn.base import clone\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def sweep_thr_timeaware(model, X_train_win, y_train_win, target=0.80, calibrate=False):\n",
    "    n = len(X_train_win)\n",
    "    cut = int(0.75 * n)\n",
    "    Xh, Xv = X_train_win.iloc[:cut], X_train_win.iloc[cut:]\n",
    "    yh, yv = (y_train_win[:cut], y_train_win[cut:]) if not hasattr(y_train_win, \"iloc\") \\\n",
    "        else (y_train_win.iloc[:cut], y_train_win.iloc[cut:])\n",
    "\n",
    "    base = clone(model)\n",
    "    base = base.fit(Xh, yh)\n",
    "\n",
    "    proba_model = base\n",
    "    if calibrate:\n",
    "        proba_model = CalibratedClassifierCV(base, method=\"isotonic\", cv=\"prefit\")\n",
    "        proba_model.fit(Xv, yv)\n",
    "\n",
    "    if not hasattr(proba_model, \"predict_proba\"):\n",
    "        return None\n",
    "\n",
    "    p = proba_model.predict_proba(Xv)[:, 1]\n",
    "    best = (0.0, 0.0, 0.50)\n",
    "    for thr in np.linspace(0.01, 0.60, 60):\n",
    "        yhat = (p >= thr).astype(int)\n",
    "        prec, rec, _, _ = precision_recall_fscore_support(yv, yhat, average=\"binary\", zero_division=0)\n",
    "        if (rec >= target and prec > best[1]) or (best[0] < target and rec > best[0]):\n",
    "            best = (rec, prec, thr)\n",
    "    return best[2]\n"
   ],
   "id": "c3a9c2f7b2475c14",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:16:07.529886Z",
     "start_time": "2025-11-23T14:12:18.510661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#p\n",
    "trained = {name: Pipeline([(\"clf\", mdl)]) for name, mdl in MODELS.items()}\n",
    "trained = {n: m.fit(Xtr, y_train) for n, m in trained.items()}\n",
    "\n",
    "# thresholds: calibrate ONLY the models that benefit (tree models). LR usually doesn’t need it.\n",
    "swept = {\n",
    "    \"lr\":  sweep_thr_timeaware(trained[\"lr\"],  Xtr, y_train, target=0.80, calibrate=False),\n",
    "    \"rf\":  sweep_thr_timeaware(trained[\"rf\"],  Xtr, y_train, target=0.80, calibrate=False),\n",
    "    \"xgb\": sweep_thr_timeaware(trained[\"xgb\"], Xtr, y_train, target=0.80, calibrate=True),\n",
    "}\n",
    "print(\"Chosen thresholds:\", swept)\n"
   ],
   "id": "d61e284270e2c14d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen thresholds: {'lr': np.float64(0.6), 'rf': np.float64(0.03), 'xgb': np.float64(0.01)}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:17:50.550899Z",
     "start_time": "2025-11-23T14:16:07.678167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#p\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def refine_thr(model, Xtr_full, ytr_full, thr0, target=0.80, window=0.03, steps=150):\n",
    "    n = len(Xtr_full); cut = int(0.75*n)\n",
    "    Xh, Xv = Xtr_full.iloc[:cut], Xtr_full.iloc[cut:]\n",
    "    yh, yv = (ytr_full[:cut], ytr_full[cut:]) if not hasattr(ytr_full, \"iloc\") \\\n",
    "        else (ytr_full.iloc[:cut], ytr_full.iloc[cut:])\n",
    "    m = clone(model).fit(Xh, yh)\n",
    "    p = m.predict_proba(Xv)[:,1]\n",
    "    lo, hi = max(0.0, thr0 - window), min(1.0, thr0 + window)\n",
    "    best = (0.0, 0.0, thr0)\n",
    "    for thr in np.linspace(lo, hi, steps):\n",
    "        yhat = (p >= thr).astype(int)\n",
    "        prec, rec, _, _ = precision_recall_fscore_support(yv, yhat, average=\"binary\", zero_division=0)\n",
    "        if (rec >= target and prec > best[1]) or (best[0] < target and rec > best[0]):\n",
    "            best = (rec, prec, thr)\n",
    "    return best[2]\n",
    "\n",
    "swept[\"xgb\"] = refine_thr(trained[\"xgb\"], Xtr, y_train, swept[\"xgb\"], target=0.80, window=0.03, steps=150)\n",
    "swept[\"lr\"]  = refine_thr(trained[\"lr\"],  Xtr, y_train, swept[\"lr\"],  target=0.80, window=0.01, steps=80)\n",
    "swept[\"rf\"] = refine_thr(trained[\"rf\"], Xtr, y_train, swept[\"rf\"], target=0.80)\n"
   ],
   "id": "a770f9eb7d4c9e68",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:17:51.676294Z",
     "start_time": "2025-11-23T14:17:50.657966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#p\n",
    "def eval_with_thr(m, X, y, thr):\n",
    "    p = m.predict_proba(X)[:, 1]\n",
    "    yhat = (p >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, yhat).ravel()\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y, yhat, average=\"binary\", zero_division=0)\n",
    "    return {\n",
    "        \"precision\": float(prec), \"recall\": float(rec), \"f1\": float(f1),\n",
    "        \"roc_auc\": float(roc_auc_score(y, p)), \"tp\": int(tp), \"fp\": int(fp),\n",
    "        \"tn\": int(tn), \"fn\": int(fn), \"alerts\": int(tp+fp), \"alert_rate\": (tp+fp)/len(y),\n",
    "        \"threshold\": float(thr)\n",
    "    }\n",
    "\n",
    "# Ensure swept[\"rf\"] contains the refined value before this\n",
    "results = {name: eval_with_thr(trained[name], Xte, y_test, swept[name])\n",
    "           for name in [\"lr\",\"rf\",\"xgb\"]}\n",
    "print(results)\n",
    "\n",
    "# CMs for both tree models (workload view)\n",
    "for name in [\"rf\",\"xgb\"]:\n",
    "    m = trained[name]; thr = swept[name]\n",
    "    p = m.predict_proba(Xte)[:,1]\n",
    "    yhat = (p >= thr).astype(int)\n",
    "    cm = confusion_matrix(y_test, yhat).tolist()\n",
    "    print(f\"{name.upper()} cm [[TN,FP],[FN,TP]]:\", cm,\n",
    "          \"| alerts=\", int((yhat==1).sum()))\n",
    "\n"
   ],
   "id": "4cf4334c94606e69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': {'precision': 0.0387858347386172, 'recall': 0.92, 'f1': 0.0744336569579288, 'roc_auc': 0.9860065275604853, 'tp': 69, 'fp': 1710, 'tn': 55177, 'fn': 6, 'alerts': 1779, 'alert_rate': np.float64(0.031231347213932094), 'threshold': 0.609746835443038}, 'rf': {'precision': 0.5169491525423728, 'recall': 0.8133333333333334, 'f1': 0.6321243523316062, 'roc_auc': 0.9540391770820515, 'tp': 61, 'fp': 57, 'tn': 56830, 'fn': 14, 'alerts': 118, 'alert_rate': np.float64(0.002071556476247323), 'threshold': 0.03221476510067114}, 'xgb': {'precision': 0.5, 'recall': 0.8, 'f1': 0.6153846153846154, 'roc_auc': 0.986530724652967, 'tp': 60, 'fp': 60, 'tn': 56827, 'fn': 15, 'alerts': 120, 'alert_rate': np.float64(0.002106667602963379), 'threshold': 0.015838926174496646}}\n",
      "RF cm [[TN,FP],[FN,TP]]: [[56830, 57], [14, 61]] | alerts= 118\n",
      "XGB cm [[TN,FP],[FN,TP]]: [[56827, 60], [15, 60]] | alerts= 120\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:18:29.700239Z",
     "start_time": "2025-11-23T14:17:51.773807Z"
    }
   },
   "source": [
    "# --- FEATURE IMPORTANCE ---\n",
    "def feat_importance(m, X, y, top=15):\n",
    "    est = m.named_steps.get('clf', m) if hasattr(m, 'named_steps') else m\n",
    "    names = list(X.columns)\n",
    "    out = {}\n",
    "    if hasattr(est, \"coef_\"):\n",
    "        vals = np.abs(est.coef_).ravel()\n",
    "        out[\"coef_abs\"] = sorted(\n",
    "            [{\"feature\": n, \"importance\": float(v)} for n, v in zip(names, vals)],\n",
    "            key=lambda d: d[\"importance\"], reverse=True\n",
    "        )[:top]\n",
    "    if hasattr(est, \"feature_importances_\"):\n",
    "        vals = est.feature_importances_\n",
    "        out[\"gini\"] = sorted(\n",
    "            [{\"feature\": n, \"importance\": float(v)} for n, v in zip(names, vals)],\n",
    "            key=lambda d: d[\"importance\"], reverse=True\n",
    "        )[:top]\n",
    "    perm = permutation_importance(est, X, y, scoring=\"f1\", n_repeats=5,\n",
    "                                  random_state=cfg['seed'], n_jobs=-1)\n",
    "    out[\"perm_f1\"] = sorted(\n",
    "        [{\"feature\": n, \"importance\": float(v)} for n, v in zip(names, perm.importances_mean)],\n",
    "        key=lambda d: d[\"importance\"], reverse=True\n",
    "    )[:top]\n",
    "    return out\n",
    "\n",
    "feat_imp=feat_importance(trained[\"rf\"],Xte,y_test)\n",
    "feat_imp"
   ],
   "id": "b21430d5aa71ca7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gini': [{'feature': 'V14', 'importance': 0.17726853459748598},\n",
       "  {'feature': 'V10', 'importance': 0.12536484970292291},\n",
       "  {'feature': 'V12', 'importance': 0.10591588178799394},\n",
       "  {'feature': 'V17', 'importance': 0.09847160743382767},\n",
       "  {'feature': 'V4', 'importance': 0.09429429965756099},\n",
       "  {'feature': 'V11', 'importance': 0.07532776719700632},\n",
       "  {'feature': 'V16', 'importance': 0.04384074747433529},\n",
       "  {'feature': 'V7', 'importance': 0.035197457266418555},\n",
       "  {'feature': 'V3', 'importance': 0.030966626460021376},\n",
       "  {'feature': 'V2', 'importance': 0.0244631462516603},\n",
       "  {'feature': 'V21', 'importance': 0.016953830745629412},\n",
       "  {'feature': 'V18', 'importance': 0.01553854797398154},\n",
       "  {'feature': 'V19', 'importance': 0.012377653977048252},\n",
       "  {'feature': 'V9', 'importance': 0.012370803249994077},\n",
       "  {'feature': 'Amount_z', 'importance': 0.011414255534963232}],\n",
       " 'perm_f1': [{'feature': 'V12', 'importance': 0.787360132615002},\n",
       "  {'feature': 'V14', 'importance': 0.7518590580732879},\n",
       "  {'feature': 'V11', 'importance': 0.45631539665238974},\n",
       "  {'feature': 'V4', 'importance': 0.31736945181317583},\n",
       "  {'feature': 'V10', 'importance': 0.24064308458070421},\n",
       "  {'feature': 'V3', 'importance': 0.12669862433098927},\n",
       "  {'feature': 'V17', 'importance': 0.0677921190420147},\n",
       "  {'feature': 'V16', 'importance': 0.050043133228616796},\n",
       "  {'feature': 'V1', 'importance': 0.044703487887073345},\n",
       "  {'feature': 'V2', 'importance': 0.01721944756905387},\n",
       "  {'feature': 'V9', 'importance': 0.01402477270986291},\n",
       "  {'feature': 'V22', 'importance': 0.011459367579052637},\n",
       "  {'feature': 'Amount_z', 'importance': 0.011428971378577724},\n",
       "  {'feature': 'V7', 'importance': 0.009559605049368836},\n",
       "  {'feature': 'V19', 'importance': 0.009529208848893921}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:18:37.535036Z",
     "start_time": "2025-11-23T14:18:29.883967Z"
    }
   },
   "source": [
    "# --- SAVE MODEL + ONNX (deterministic) ---\n",
    "from pathlib import Path\n",
    "import joblib, json\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from onnxmltools.convert import convert_xgboost\n",
    "from onnxconverter_common.data_types import FloatTensorType as FloatTensorType2\n",
    "import onnxruntime as ort\n",
    "import time\n",
    "\n",
    "models_dir = resolve_project_relative(\"ml-model/models\")\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _write_class_labels_sidecar(best_model, n_features: int, out_path: Path):\n",
    "    est = best_model.named_steps[\"clf\"] if hasattr(best_model, \"named_steps\") and \"clf\" in best_model.named_steps else best_model\n",
    "    if not hasattr(est, \"classes_\"):\n",
    "        raise RuntimeError(\"Model has no classes.\")\n",
    "    labels = est.classes_.tolist()\n",
    "    labels = [int(x) if x in (0, 1) or str(x) in (\"0\", \"1\") else str(x) for x in labels]\n",
    "    sidecar = {\n",
    "        \"class_labels\": labels,\n",
    "        \"positive_label\": 1 if 1 in labels else \"fraud\",\n",
    "        \"n_features\": int(n_features)\n",
    "    }\n",
    "    out_path.write_text(json.dumps(sidecar, indent=2))\n",
    "\n",
    "def export_onnx(best_name, best_model, X_ref):\n",
    "    n_features = X_ref.shape[1]\n",
    "    onnx_path = models_dir / \"best_model.onnx\"\n",
    "    joblib.dump(best_model, models_dir / \"best_model.joblib\")\n",
    "\n",
    "    # unwrap pipeline if present\n",
    "    est = best_model.named_steps[\"clf\"] if hasattr(best_model, \"named_steps\") and \"clf\" in best_model.named_steps else best_model\n",
    "\n",
    "    if best_name in (\"lr\", \"lr_smote\", \"rf\"):\n",
    "        onx = convert_sklearn(\n",
    "            best_model,  # pipeline is fine here\n",
    "            initial_types=[(\"input\", FloatTensorType([None, n_features]))],\n",
    "            target_opset=15,\n",
    "            options={\"zipmap\": False}\n",
    "        )\n",
    "        onnx_path.write_bytes(onx.SerializeToString())\n",
    "\n",
    "    elif best_name == \"xgb\":\n",
    "        onx = convert_xgboost(\n",
    "            est,\n",
    "            initial_types=[(\"input\", FloatTensorType2([None, n_features]))]\n",
    "        )\n",
    "        onnx_path.write_bytes(onx.SerializeToString())\n",
    "    else:\n",
    "        raise RuntimeError(f\"ONNX export not implemented for model '{best_name}'\")\n",
    "\n",
    "    _write_class_labels_sidecar(best_model, n_features, models_dir / \"class_labels.json\")\n",
    "    return str(onnx_path)\n",
    "\n",
    "# ---- choose RF explicitly ----\n",
    "model_name = \"rf\"\n",
    "best      = trained[model_name]\n",
    "best_thr  = float(swept[model_name])\n",
    "\n",
    "onnx_file = export_onnx(model_name, best, Xtr)\n",
    "\n",
    "# sanity-load the ONNX\n",
    "sess = ort.InferenceSession(onnx_file, providers=[\"CPUExecutionProvider\"])\n",
    "print(\"ONNX OK ->\", onnx_file)\n"
   ],
   "id": "420cf4aa2431080c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX OK -> /home/k1rel/programming/rt-fraud-detection/ml-model/models/best_model.onnx\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:18:37.909979Z",
     "start_time": "2025-11-23T14:18:37.664765Z"
    }
   },
   "source": [
    "def bench(m, X, n=cfg['timing_samples']):\n",
    "    n = min(n, len(X))\n",
    "    Xs = X.iloc[:n]\n",
    "    _ = m.predict(Xs.iloc[:32])     # warm-up\n",
    "    t0 = time.perf_counter(); _ = m.predict(Xs); t1 = time.perf_counter()\n",
    "    return 1000.0 * (t1 - t0) / n\n",
    "\n",
    "sk_ms = bench(best, Xte)\n",
    "\n",
    "onnx_ms = None\n",
    "pname = sess.get_inputs()[0].name\n",
    "Xarr = Xte.values.astype(np.float32)\n",
    "n = min(cfg['timing_samples'], len(Xarr))\n",
    "_ = sess.run(None, {pname: Xarr[:32]})  # warm-up\n",
    "t0 = time.perf_counter(); _ = sess.run(None, {pname: Xarr[:n]}); t1 = time.perf_counter()\n",
    "onnx_ms = 1000.0 * (t1 - t0) / n\n",
    "\n",
    "print({'sk_ms': sk_ms, 'onnx_ms': onnx_ms, 'threshold': best_thr})"
   ],
   "id": "74ceba16563b6a80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sk_ms': 0.012351150899939966, 'onnx_ms': 0.00531318690000262, 'threshold': 0.03221476510067114}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:18:37.945229Z",
     "start_time": "2025-11-23T14:18:37.935747Z"
    }
   },
   "source": [
    "# --- REPORT (compact, serializable, reproducible) ---\n",
    "from pathlib import Path\n",
    "import json, datetime, numpy as np\n",
    "\n",
    "rep = resolve_project_relative(\"ml-model/reports/model_evaluation.md\")\n",
    "\n",
    "rep.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "best_name = \"rf\"\n",
    "best_thr  = float(swept[best_name])\n",
    "\n",
    "def _to_native(o):\n",
    "    if isinstance(o, (np.floating, np.integer)): return o.item()\n",
    "    if isinstance(o, np.ndarray): return o.tolist()\n",
    "    return o\n",
    "\n",
    "report = {\n",
    "    \"timestamp_utc\": datetime.datetime.utcnow().isoformat(timespec=\"seconds\")+\"Z\",\n",
    "    \"chosen_model\": best_name,\n",
    "    \"threshold\": best_thr,\n",
    "    \"test_metrics\": {k: _to_native(v) for k,v in results[best_name].items()},\n",
    "    \"baselines\": {\n",
    "        \"lr\":  {k: _to_native(v) for k,v in results[\"lr\"].items()},\n",
    "        \"rf\":  {k: _to_native(v) for k,v in results[\"rf\"].items()},\n",
    "        \"xgb\": {k: _to_native(v) for k,v in results[\"xgb\"].items()}\n",
    "    },\n",
    "    \"cv_results\": {m: {k: _to_native(v) for k,v in d.items()} for m,d in cv_results.items()} if \"cv_results\" in globals() else {},\n",
    "    \"timing_ms_per_row\": {\"sklearn\": float(sk_ms), \"onnx\": float(onnx_ms)},\n",
    "    \"thresholds\": {k: float(v) for k,v in swept.items()},\n",
    "    \"feature_importance_top15\": feat_imp\n",
    "}\n",
    "\n",
    "rep.write_text(\n",
    "    '# Model Evaluation\\n\\n```json\\n'\n",
    "    + json.dumps(report, indent=2)\n",
    "    + '\\n```\\n',\n",
    "    encoding='utf-8'\n",
    ")\n",
    "print('Report written ->', rep)\n"
   ],
   "id": "ff7b20f9239bf03c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report written -> /home/k1rel/programming/rt-fraud-detection/ml-model/reports/model_evaluation.md\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
