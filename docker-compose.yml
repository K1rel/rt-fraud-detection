services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    container_name: zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD-SHELL", "bash -lc '</dev/tcp/127.0.0.1/2181'"]
      interval: 10s
      timeout: 5s
      retries: 20

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092" # internal
      - "29092:29092" # external
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"

      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

      KAFKA_TRANSACTION_MAX_TIMEOUT_MS: "3600000"
    healthcheck:
      test: ["CMD-SHELL", "bash -lc 'kafka-topics --bootstrap-server localhost:9092 --list >/dev/null 2>&1'"]
      interval: 10s
      timeout: 10s
      retries: 30

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.14.1
    container_name: elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    healthcheck:
      test: [ "CMD-SHELL", "curl -sf http://localhost:9200/_cluster/health | grep -E '\"status\":\"(yellow|green)\"' >/dev/null" ]
      interval: 15s
      timeout: 10s
      retries: 40

  kibana:
    image: docker.elastic.co/kibana/kibana:8.14.1
    container_name: kibana
    restart: unless-stopped
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    healthcheck:
      test: [ "CMD-SHELL", "curl -sf http://localhost:5601/api/status | grep 'overall' >/dev/null" ]
      interval: 20s
      timeout: 10s
      retries: 30
  jobmanager:
    image: apache/flink:2.0.0-java17
    container_name: flink-jobmanager
    command: jobmanager
    environment:
      - LOG4J_CONFIGURATION_FILE=/opt/flink/conf/log4j2.properties
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - TRANSACTIONS_TOPIC=transactions
      - KAFKA_CONSUMER_GROUP=fraud-detector
      - FLINK_CHECKPOINT_INTERVAL_MS=60000
      - FLINK_DEFAULT_PARALLELISM=4
      - ONNX_MODEL_SRC=resource
      - ONNX_MODEL_RESOURCE=/model/best_model.onnx
      - MODEL_VERSION=best_model.onnx
#      - RULE_MAX_TX_PER_MINUTE=5
#      - RULE_FREQUENCY_WINDOW_MS=60000
#      - RULE_HIGH_AMOUNT_THRESHOLD=5000
#      - RULE_VELOCITY_MIN_GAP_MS=5000
#      - RULE_MODEL_SCORE_THRESHOLD=0.8
#      - ML_FRAUD_THRESHOLD=0.5
#      - ALERT_SCORE_THRESHOLD=0.8
      - RULE_MAX_TX_PER_MINUTE=1          # flag freq on almost every account hit
      - RULE_FREQUENCY_WINDOW_MS=60000
      - RULE_HIGH_AMOUNT_THRESHOLD=10     # anything >10 EUR is "high"
      - RULE_VELOCITY_MIN_GAP_MS=60000    # disable velocity (needs < 60s)
      - RULE_MODEL_SCORE_THRESHOLD=0.1    # ANY score -> HIGH_MODEL_SCORE
      - ML_FRAUD_THRESHOLD=0.05
      - ALERT_SCORE_THRESHOLD=0.08

      - ALERTS_TOPIC=fraud_alerts
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - ELASTICSEARCH_SCHEME=HTTP
      - ELASTICSEARCH_ALERT_INDEX_PREFIX=fraud-alerts
    restart: unless-stopped
    ports:
      - "8081:8081"
      - "9249:9249"
    volumes:
      - ./flink/conf/config.yaml:/opt/flink/conf/config.yaml:ro
      - ./flink/conf/log4j2.properties:/opt/flink/conf/log4j2.properties:ro
      - flink-logs:/opt/flink/log
      - ./flink/remote:/remote
      - ./flink/lib/flink-metrics-prometheus-2.0.0.jar:/opt/flink/lib/flink-metrics-prometheus-2.0.0.jar:ro
    healthcheck:
      test: [ "CMD-SHELL", "curl -sf http://localhost:8081/overview >/dev/null" ]
      interval: 10s
      timeout: 5s
      retries: 30

  taskmanager:
    image: apache/flink:2.0.0-java17
    command: taskmanager
    restart: unless-stopped
    depends_on:
      - jobmanager
    environment:
      - LOG4J_CONFIGURATION_FILE=/opt/flink/conf/log4j2.properties
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - TRANSACTIONS_TOPIC=transactions
      - KAFKA_CONSUMER_GROUP=fraud-detector
      - FLINK_CHECKPOINT_INTERVAL_MS=60000
      - FLINK_DEFAULT_PARALLELISM=4
      - ONNX_MODEL_SRC=resource
      - ONNX_MODEL_RESOURCE=/model/best_model.onnx
      - MODEL_VERSION=best_model.onnx
    volumes:
      - ./flink/conf/config.yaml:/opt/flink/conf/config.yaml:ro
      - ./flink/conf/log4j2.properties:/opt/flink/conf/log4j2.properties:ro
      - flink-logs:/opt/flink/log
      - ./flink/remote:/remote
      - ./flink/lib/flink-metrics-prometheus-2.0.0.jar:/opt/flink/lib/flink-metrics-prometheus-2.0.0.jar:ro
  api:
    build:
      context: ./api
    container_name: api
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=3001
      - ELASTICSEARCH_NODE=http://elasticsearch:9200
    ports:
      - "3001:3001"
    depends_on:
      - elasticsearch


volumes:
 esdata: { }
 flink-logs: {}

networks:
 default:
   name: fraud-detection-net


